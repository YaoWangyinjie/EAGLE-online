online:
python -m EAGLE-online.eagle.evaluation.gen_ea_answer_llama3chat \
--ea-model-path model_weight/EAGLE3-DeepSeek-R1-Distill-LLaMA-8B/ \
--base-model-path model_weight/DeepSeek-R1-Distill-Llama-8B/ \
--use_eagle3 \
--enable-online-adaptation \
--model-id 0

baseline:
python -m EAGLE.eagle.evaluation.gen_ea_answer_llama3chat \
--ea-model-path model_weight/EAGLE3-DeepSeek-R1-Distill-LLaMA-8B/ \
--base-model-path model_weight/DeepSeek-R1-Distill-Llama-8B/ \
--use_eagle3 \
--model-id 0

outside:
/mt_bench
/mt_bench_online
/model_weight: download from github
/analysis_report

每次clone后修改：
gen_ea_answer_llama3chat.py中可用gpu数量
配置debug，注意添加python的路径为which python
配置环境按requirements安装后调整torch==2.6.0,torchvision==0.21.0,torchaudio==2.6.0

解决问题：
reset：是否需要使用，保存状态并恢复是否正常
词表对齐：可能有问题
数据类型转换：训练结束时是否复原数据类型状态
prompt引入后使用的hidden state：前文使用具体哪一个hidden state，训练时具体调用哪个hidden state
持续状态：累积的权重和cache产生污染，需要合理清空
超参：lr，temperature
